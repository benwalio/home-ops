---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: minio
  namespace: storage
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 1.3.2
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    controller:
      annotations:
        reloader.stakater.com/auto: "true"
    image:
      repository: quay.io/minio/minio
      tag: RELEASE.2023-01-18T04-36-38Z
    env:
      TZ: ${TIMEZONE}
      MINIO_UPDATE: "off"
      # MINIO_PROMETHEUS_URL: http://kube-prometheus-stack-prometheus.monitoring.svc.cluster.local:9090
      MINIO_PROMETHEUS_JOB_ID: minio
      MINIO_BROWSER_REDIRECT_URL: https://minio.${SECRET_DOMAIN}
      MINIO_SERVER_URL: https://s3.${SECRET_DOMAIN}
      MINIO_API_CORS_ALLOW_ORIGIN: https://minio.${SECRET_DOMAIN},https://s3.${SECRET_DOMAIN}
    envFrom:
      - secretRef:
          name: minio-secret
    args: ["server", "/data", "--console-address", ":9001"]
    service:
      main:
        enabled: true
        ports:
          http:
            port: &console-port 9001
          api:
            enabled: true
            port: &api-port 9000
    serviceMonitor:
      main:
        enabled: false
        # endpoints:
        #   - port: api
        #     scheme: http
        #     path: /minio/v2/metrics/cluster
        #     interval: 1m
        #     scrapeTimeout: 10s
        #     bearerTokenSecret:
        #       name: minio-secret
        #       key: MINIO_PROMETHEUS_TOKEN
    probes:
      liveness: &probes
        enabled: true
        custom: true
        spec:
          httpGet:
            path: /minio/health/live
            port: *api-port
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 1
          failureThreshold: 3
      readiness: *probes
      startup:
        enabled: false
    ingress:
      main:
        enabled: true
        ingressClassName: nginx
        annotations:
          hajimari.io/icon: mdi:pail
          hajimari.io/enable: "true"
          external-dns.home.arpa/enabled: "false"
          nginx.ingress.kubernetes.io/proxy-ssl-verify: "off"
          nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
          nginx.ingress.kubernetes.io/rewrite-target: /
          nginx.ingress.kubernetes.io/proxy-body-size: "0"
          nginx.ingress.kubernetes.io/server-snippet: |
            client_max_body_size 0;
          nginx.ingress.kubernetes.io/configuration-snippet: |
            chunked_transfer_encoding off;
        hosts:
          - host: &console-host "{{ .Release.Name }}.${SECRET_DOMAIN}"
            paths:
              - path: /
                pathType: Prefix
                service:
                  port: *console-port
        tls:
          - hosts:
              - *console-host
      s3:
        enabled: true
        ingressClassName: nginx
        annotations:
          external-dns.home.arpa/enabled: "true"
          external-dns.alpha.kubernetes.io/target: "ipv4.${SECRET_DOMAIN}"
          nginx.ingress.kubernetes.io/proxy-connect-timeout: "180"
          nginx.ingress.kubernetes.io/proxy-ssl-verify: "off"
          nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
          nginx.ingress.kubernetes.io/rewrite-target: /
          nginx.ingress.kubernetes.io/proxy-body-size: "0"
          nginx.ingress.kubernetes.io/server-snippet: |
            client_max_body_size 0;
          nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
          nginx.ingress.kubernetes.io/configuration-snippet: |
            chunked_transfer_encoding off;
          hajimari.io/enable: "false"
        hosts:
          - host: &api-host s3.${SECRET_DOMAIN}
            paths:
              - path: /
                pathType: Prefix
                service:
                  port: *api-port
        tls:
          - hosts:
              - *api-host
    podSecurityContext:
      runAsUser: 1100
      runAsGroup: 1100
      fsGroup: 1100
      fsGroupChangePolicy: "OnRootMismatch"
      # supplementalGroups:
      #   - 100
    persistence:
      config:
        enabled: true
        existingClaim: minio-nfs
        mountPath: /data
    resources:
      requests:
        memory: 100Mi
        cpu: 100m
      limits:
        memory: 750Mi
